{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, shutil,cv2,imutils\n",
    "import matplotlib.image as mpimg\n",
    "# Use \"conda install -c conda-forge scikit-image\" incase skimage install throws error\n",
    "from skimage.filters import threshold_local\n",
    "import requests, re\n",
    "# If you are using a Jupyter notebook, uncomment the following line.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for the different shapes and pattern match\n",
    "\n",
    "class ShapeDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def detect(self, c):\n",
    "        # initialize the shape name and approximate the contour\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "\n",
    "        # if the shape has 4 vertices, it is either a square or\n",
    "        # a rectangle\n",
    "        if len(approx) == 4:\n",
    "            # compute the bounding box of the contour and use the\n",
    "            # bounding box to compute the aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    "\n",
    "            # a square will have an aspect ratio that is approximately\n",
    "            # equal to one, otherwise, the shape is a rectangle\n",
    "            shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    "\n",
    "        # otherwise, we assume the shape is a circle\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    "\n",
    "        # return the name of the shape\n",
    "        return shape\n",
    "        \n",
    "# Class for matching different date format\n",
    "class DateMatch:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def dateandtime_match(self,text):\n",
    "        \n",
    "        match = re.search(r'(\\d+/\\d+/\\d+)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^[0-3]?[0-9]/[0-3]?[0-9]/(?:[0-9]{2})?[0-9]{2}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^[0-3][0-9]/[0-3][0-9]/(?:[0-9][0-9])?[0-9][0-9]$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(1[0-2]|0?[1-9])/(3[01]|[12][0-9]|0?[1-9])/(?:[0-9]{2})?[0-9]{2}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(1[0-2]|0[1-9])/(3[01]|[12][0-9]|0[1-9])/[0-9]{4}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(3[01]|[12][0-9]|0?[1-9])/(1[0-2]|0?[1-9])/(?:[0-9]{2})?[0-9]{2}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(3[01]|[12][0-9]|0[1-9])/(1[0-2]|0[1-9])/[0-9]{4}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(?:(1[0-2]|0?[1-9])/(3[01]|[12][0-9]|0?[1-9])|(3[01]|[12][0-9]|0?[1-9])/(1[0-2]|0?[1-9]))/(?:[0-9]{2})?[0-9]{2}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(?:(1[0-2]|0?[1-9])/(3[01]|[12][0-9]|0?[1-9])|(3[01]|[12][0-9]|0?[1-9])/(1[0-2]|0?[1-9]))/(?:[0-9]{2})?[0-9]{2}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(?:(1[0-2]|0[1-9])/(3[01]|[12][0-9]|0[1-9])|(3[01]|[12][0-9]|0[1-9])/(1[0-2]|0[1-9]))/[0-9]{4}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        match = re.search(r'(^(?:(1[0-2]|0[1-9])/(3[01]|[12][0-9]|0[1-9])|(3[01]|[12][0-9]|0[1-9])/(1[0-2]|0[1-9]))/[0-9]{4}$)',text)\n",
    "        return None if match is None else match is True\n",
    "        \n",
    "        return match\n",
    "\n",
    "\n",
    "# Class for matching common words in receipts\n",
    "class CommonWords:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def word_match(self,text):\n",
    "        \n",
    "        patterns = ['Total','TOTAL','total','Amount','amount','AMOUNT','Cash','cash','CASH','Thank You','thank you','Thank you',\n",
    "                    'THANK YOU','Thank You!','thank you!','Thank you!','THANK YOU!','card','Card','CARD','Debit','debit','DEBIT',\n",
    "                    'Credit','credit','CREDIT','Item','item','ITEM','QTY','qty','QUANTITY','quantity','Quantity','TAX','Tax','tax',\n",
    "                    'Receipt','receipt','RECEIPT','Balance','balance','BALANCE','Price','price','PRICE','Customer','customer','CUSTOMER',\n",
    "                    'Merchant','merchant','MERCHANT','Items','items','ITEMS','@','.com','.COM','email','EMAIL',':','Please','please',\n",
    "                    'PLEASE','Welcome','welcome','WELCOME','thanks','Thanks','THANKS','MEAL','meal','Meal','chng','Chng','CHNG'\n",
    "                    '#','-','Call','call','CALL','again','Again','AGAIN','&','Transaction','transaction','TRANSACTION','$',\n",
    "                    'subtotal','Subtotal','SUBTOTAL']\n",
    "        \n",
    "        wordcount = 0\n",
    "        # Match for the words\n",
    "        for pattern in patterns:\n",
    "            if re.search(pattern,text):\n",
    "                wordcount +=1\n",
    "                       \n",
    "        return wordcount       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for fourier transform\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4,2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them\n",
    "    # individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the\n",
    "    # maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the\n",
    "    # maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct\n",
    "    # the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points\n",
    "    # in the top-left, top-right, bottom-right, and bottom-left\n",
    "    # order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shapeDetect(image):\n",
    "\n",
    "    # load the image and compute the ratio of the old height\n",
    "    # to the new height, clone it, and resize it\n",
    "    image = mpimg.imread(image)\n",
    "    ratio = image.shape[0] / 500.0\n",
    "    orig = image.copy()\n",
    "    fortext = \"Original.png\"\n",
    "    cv2.imwrite(fortext,image)\n",
    "    image = imutils.resize(image, height = 500)\n",
    "\n",
    "    # convert the image to grayscale, blur it, and find edges in the image\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "    # show the original image and the edge detected image \n",
    "    # find the contours in the edged image, keeping only the\n",
    "    # largest ones, and initialize the screen contour\n",
    "    cnts = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        # if our approximated contour has four points, then we can assume that we have found our screen\n",
    "        if len(approx) == 4:\n",
    "            screenCnt = approx\n",
    "            # show the contour (outline) of the piece of paper\n",
    "            cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "            #print(\"Yes!, it has four edges\")\n",
    "            break\n",
    "            \n",
    "    #Save the image to project directory\n",
    "    edged = \"{}.png\".format(os.getpid())\n",
    "    cv2.imwrite(edged,image)\n",
    "    \n",
    "    \"\"\"\n",
    "    #Read the edged Image to detect the shape\n",
    "    image = cv2.imread(edged)\n",
    "    #orig = image.copy()\n",
    "    resized = imutils.resize(image, width=300)\n",
    "    ratio_ = image.shape[0] / float(resized.shape[0])\n",
    "    #os.remove(edged)\n",
    "    \n",
    "    # convert the resized image to grayscale, blur it slightly,\n",
    "    # and threshold it\n",
    "    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.threshold(blurred, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # find contours in the thresholded image and initialize the\n",
    "    # shape detector\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    sd = ShapeDetector()\n",
    "\n",
    "   \n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # compute the center of the contour, then detect the name of the\n",
    "        # shape using only the contour\n",
    "        M = cv2.moments(c)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int((M[\"m10\"] / M[\"m00\"]) * ratio_)\n",
    "            cY = int((M[\"m01\"] / M[\"m00\"]) * ratio_)\n",
    "            shape = sd.detect(c)\n",
    "            if shape == \"rectangle\":\n",
    "                receipt = True\n",
    "                break\n",
    "            else:\n",
    "                receipt = False\n",
    "               \n",
    "        else:\n",
    "        \n",
    "            font = cv2.FONT_HERSHEY_COMPLEX\n",
    "            approx = cv2.approxPolyDP(c, 0.01*cv2.arcLength(c, True), True)\n",
    "            x = approx.ravel()[0]\n",
    "            y = approx.ravel()[1]\n",
    "            if len(approx) == 4:\n",
    "                receipt = True\n",
    "                break\n",
    "            else:\n",
    "                receipt = False\n",
    "            \n",
    "    if receipt == True:\n",
    "        # Add part here to scan the image and apply OCR on it instead of print statement\n",
    "        print(\"Yes!, it has four edge\")\n",
    "    else:\n",
    "        print(\"No! not with four edge\")\n",
    "    \n",
    "    \"\"\"\n",
    "    os.remove(edged)\n",
    "    # apply the four point transform to obtain a top-down\n",
    "    # view of the original image\n",
    "    warped = four_point_transform(orig, screenCnt.reshape(4,2) * ratio)\n",
    " \n",
    "    # convert the warped image to grayscale, then threshold it\n",
    "    # to give it that 'black and white' paper effect\n",
    "    warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    T = threshold_local(warped,11, offset = 10, method = \"mean\")\n",
    "    warped = (warped > T).astype(\"uint8\") * 255\n",
    " \n",
    "    # show the original and scanned images\n",
    "    output = \"Output.png\"\n",
    "    cv2.imwrite(output, imutils.resize(warped, height = 650))   \n",
    "    \n",
    "    # Text detection\n",
    "    # Replace <Subscription Key> with your valid subscription key.\n",
    "    subscription_key = \"3c1471dee9084c4587fc64cbb0d225dd\"\n",
    "    assert subscription_key\n",
    "\n",
    "    # You must use the same region in your REST call as you used to get your subscription keys. For example, if you got your \n",
    "    #subscription keys from westus, replace \"westcentralus\" in the URI below with \"westus\".Free trial subscription keys are generated in the \"westus\" region.\n",
    "    # If you use a free trial subscription key, you shouldn't need to change this region.\n",
    "\n",
    "    vision_base_url = \"https://westus.api.cognitive.microsoft.com/vision/v2.0/\"\n",
    "    ocr_url = vision_base_url + \"ocr\"\n",
    "\n",
    "    # Set image_url to the URL of an image that you want to analyze.\n",
    "\n",
    "    #file_name = orig.copy()\n",
    "    with open(output, 'rb') as f:\n",
    "        img_data = f.read()\n",
    "\n",
    "    headers = {'Content-Type': 'application/octet-stream','Ocp-Apim-Subscription-Key': subscription_key}\n",
    "    params = {'language': 'unk', 'detectOrientation': 'true'}\n",
    "    response = requests.post(ocr_url,headers=headers,params=params,data=img_data)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    response\n",
    "    analysis = response.json()\n",
    "\n",
    "    # Extract the word bounding boxes and text.\n",
    "    line_infos = [region[\"lines\"] for region in analysis[\"regions\"]]\n",
    "    word_infos = []\n",
    "    for line in line_infos:\n",
    "        for word_metadata in line:\n",
    "            for word_info in word_metadata[\"words\"]:\n",
    "                word_infos.append(word_info)\n",
    "\n",
    "    for word in word_infos:\n",
    "        bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "        text = word[\"text\"]\n",
    "        origin = (bbox[0], bbox[1])\n",
    "        patch = Rectangle(origin, bbox[2], bbox[3],fill=False, linewidth=2, color='y')\n",
    "\n",
    "    text = ''\n",
    "    for item in response.json()['regions']:\n",
    "        for line in item['lines']:\n",
    "            for word in line['words']:\n",
    "                text +=' ' + word['text']\n",
    "            text += '\\n'\n",
    "    data = open(\"text.txt\", 'w+')\n",
    "    data.write(text)\n",
    "    data.close()\n",
    "    \n",
    "    # Open the text file and read the content for the patterns matching\n",
    "    data1 = open(\"text.txt\", 'r')\n",
    "    text1 = data1.read()\n",
    "    dm = DateMatch()\n",
    "    pattern1 = dm.dateandtime_match(text1)\n",
    "    cw = CommonWords()\n",
    "    pattern2 = cw.word_match(text1)\n",
    "    data1.close()\n",
    "    os.remove(\"text.txt\")\n",
    "    os.remove(output)\n",
    "    os.remove(fortext)\n",
    "    \n",
    "    # Moment of the truth\n",
    "    if pattern1 == True or pattern2 >= 2:\n",
    "        #print(\"Yes! It is a receipt\")\n",
    "        isreceipt = True\n",
    "    else:\n",
    "        #print(\"Sorry! Please upload a receipt\")\n",
    "        isreceipt = False\n",
    "\n",
    "    return isreceipt\n",
    "\n",
    "#shapeDetect(\"b.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p1",
   "language": "python",
   "name": "p1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
